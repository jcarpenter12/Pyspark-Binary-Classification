{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import findspark\n",
    "import time\n",
    "import os.path\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.mllib.tree import RandomForest, RandomForestModel\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer, VectorAssembler, OneHotEncoder, SQLTransformer\n",
    "from pyspark.ml.linalg import DenseVector\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.sql import SQLContext, Row\n",
    "from pyspark.sql.functions import translate,lit,col,isnan,count,when,split,explode,ltrim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot run multiple SparkContexts at once; existing SparkContext(app=Classifier, master=local[*]) created by __init__ at <ipython-input-158-8f4850d1539f>:3 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-212-8f4850d1539f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m#initialise spark\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfindspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparkContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mappName\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Classifier'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0msql\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSQLContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pyspark\\context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \"\"\"\n\u001b[1;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callsite\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfirst_spark_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mCallSite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[0;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pyspark\\context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    297\u001b[0m                         \u001b[1;34m\" created by %s at %s:%s \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                         % (currentAppName, currentMaster,\n\u001b[0;32m--> 299\u001b[0;31m                             callsite.function, callsite.file, callsite.linenum))\n\u001b[0m\u001b[1;32m    300\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                     \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=Classifier, master=local[*]) created by __init__ at <ipython-input-158-8f4850d1539f>:3 "
     ]
    }
   ],
   "source": [
    "#initialise spark\n",
    "findspark.init()\n",
    "sc = pyspark.SparkContext(appName='Classifier')\n",
    "sql = pyspark.SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_dataframes(directory):\n",
    "    \"\"\"\n",
    "    Creates dataframes from directory\n",
    "    Must be named 'train' or 'test'. \n",
    "    Returns only train if test N/A\n",
    "    \n",
    "    Inputs: String \n",
    "    \n",
    "    Returns: Dataframes/Dataframe\n",
    "    \n",
    "    \"\"\"\n",
    "    if os.path.exists(directory):\n",
    "        train = directory+\"/train.csv\"\n",
    "        if os.path.exists(train):\n",
    "            df_train = sql.read.csv(train, \n",
    "                         header = True,\n",
    "                         inferSchema = True)\n",
    "        else:\n",
    "            raise ValueError(\"train.csv not found in %s\" % directory)\n",
    "        \n",
    "        test = directory+\"/test.csv\"\n",
    "        if os.path.exists(test):\n",
    "            df_test = sql.read.csv(train, \n",
    "                         header = True,\n",
    "                         inferSchema = True)\n",
    "            return df_train,df_test\n",
    "        \n",
    "        return df_train\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"%s does not exist\" % directory)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train,df_test= create_dataframes('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# combine train and test\n",
    "df_train = df_train.withColumn('Mark',lit('train'))\n",
    "df_test  = df_test.withColumn('Mark',lit('test'))\n",
    "df = df_train.unionAll(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values for PassengerId : 0\n",
      "Missing values for Survived : 0\n",
      "Missing values for Pclass : 0\n",
      "Missing values for Name : 0\n",
      "Missing values for Sex : 0\n",
      "Missing values for Age : 354\n",
      "Missing values for SibSp : 0\n",
      "Missing values for Parch : 0\n",
      "Missing values for Ticket : 0\n",
      "Missing values for Fare : 0\n",
      "Missing values for Cabin : 1374\n",
      "Missing values for Embarked : 4\n",
      "Missing values for Mark : 0\n"
     ]
    }
   ],
   "source": [
    "#missing values by column\n",
    "for col in df.columns:\n",
    "    missing = df.where(df[col].isNull()).count()\n",
    "    print(\"Missing values for %s : %s\" % (col,missing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cabin has a high amount of missing values so I will remove it \n",
    "df = df.drop('Cabin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fill missing values with the mean\n",
    "def fill_null_with_mean(df):\n",
    "    \"\"\"\n",
    "    Replaces null numeric values with\n",
    "    mean value\n",
    "    \n",
    "    input: spark dataframe\n",
    "    returns: spark dataframe\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    x = df.cache()\n",
    "    \n",
    "    for col in df.schema.fields:\n",
    "        dtype = \"%s\" % col.dataType\n",
    "        if dtype != \"StringType\":\n",
    "            mean = df.groupBy().mean(col.name).first()[0]\n",
    "            x = x.na.fill({col.name:mean})\n",
    "            \n",
    "    return x\n",
    "\n",
    "df = fill_null_with_mean(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#replace categorical with mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "translate() missing 2 required positional arguments: 'matching' and 'replace'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-289-94de7514df1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[1;31m#x = df['Title'].map(Title_Dictionary)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTitle_Dictionary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Title'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: translate() missing 2 required positional arguments: 'matching' and 'replace'"
     ]
    }
   ],
   "source": [
    "#Title cleanse \n",
    "df = df.withColumn('name_split',split('Name',', ')[1])\n",
    "df= df.withColumn('Title',ltrim(split('name_split','. ')[0]))\n",
    "df.drop('name_split')\n",
    "Title_Dictionary = {\n",
    "    \"Capt\":       \"Officer\",\n",
    "    \"Col\":        \"Officer\",\n",
    "    \"Major\":      \"Officer\",\n",
    "    \"Jonkheer\":   \"Sir\",\n",
    "    \"Don\":        \"Sir\",\n",
    "    \"Sir\" :       \"Sir\",\n",
    "    \"Dr\":         \"Mr\",\n",
    "    \"Rev\":        \"Mr\",\n",
    "    \"the Countess\":\"Lady\",\n",
    "    \"Dona\":       \"Lady\",\n",
    "    \"Mme\":        \"Mrs\",\n",
    "    \"Mlle\":       \"Miss\",\n",
    "    \"Ms\":         \"Mrs\",\n",
    "    \"Mr\" :        \"Mr\",\n",
    "    \"Mrs\" :       \"Mrs\",\n",
    "    \"Miss\" :      \"Miss\",\n",
    "    \"Master\" :    \"Master\",\n",
    "    \"Lady\" :      \"Lady\"\n",
    "}\n",
    "\n",
    "#x = df['Title'].map(Title_Dictionary)\n",
    "df.withColumn('test',translate(Title_Dictionary)('Title'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "| Title|\n",
      "+------+\n",
      "|    Mr|\n",
      "|   Mrs|\n",
      "|  Miss|\n",
      "|   Mrs|\n",
      "|    Mr|\n",
      "|    Mr|\n",
      "|    Mr|\n",
      "|Master|\n",
      "|   Mrs|\n",
      "|   Mrs|\n",
      "|  Miss|\n",
      "|  Miss|\n",
      "|    Mr|\n",
      "|    Mr|\n",
      "|  Miss|\n",
      "|   Mrs|\n",
      "|Master|\n",
      "|    Mr|\n",
      "|   Mrs|\n",
      "|   Mrs|\n",
      "+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x.select('Title').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+-----------------+-----+-----+----------------+-------+--------+-----+--------------------+------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex|              Age|SibSp|Parch|          Ticket|   Fare|Embarked| Mark|          name_split| Title|\n",
      "+-----------+--------+------+--------------------+------+-----------------+-----+-----+----------------+-------+--------+-----+--------------------+------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|             22.0|    1|    0|       A/5 21171|   7.25|       S|train|     Mr. Owen Harris|    Mr|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|             38.0|    1|    0|        PC 17599|71.2833|       C|train|Mrs. John Bradley...|   Mrs|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|             26.0|    0|    0|STON/O2. 3101282|  7.925|       S|train|         Miss. Laina|  Miss|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|             35.0|    1|    0|          113803|   53.1|       S|train|Mrs. Jacques Heat...|   Mrs|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|             35.0|    0|    0|          373450|   8.05|       S|train|   Mr. William Henry|    Mr|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|29.69911764705882|    0|    0|          330877| 8.4583|       Q|train|           Mr. James|    Mr|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|             54.0|    0|    0|           17463|51.8625|       S|train|       Mr. Timothy J|    Mr|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male|              2.0|    3|    1|          349909| 21.075|       S|train|Master. Gosta Leo...|Master|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|             27.0|    0|    2|          347742|11.1333|       S|train|Mrs. Oscar W (Eli...|   Mrs|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|             14.0|    1|    0|          237736|30.0708|       C|train|Mrs. Nicholas (Ad...|   Mrs|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female|              4.0|    1|    1|         PP 9549|   16.7|       S|train|Miss. Marguerite Rut|  Miss|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|             58.0|    0|    0|          113783|  26.55|       S|train|     Miss. Elizabeth|  Miss|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|             20.0|    0|    0|       A/5. 2151|   8.05|       S|train|   Mr. William Henry|    Mr|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|             39.0|    1|    5|          347082| 31.275|       S|train|    Mr. Anders Johan|    Mr|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|             14.0|    0|    0|          350406| 7.8542|       S|train|Miss. Hulda Amand...|  Miss|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|             55.0|    0|    0|          248706|   16.0|       S|train|Mrs. (Mary D King...|   Mrs|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male|              2.0|    4|    1|          382652| 29.125|       Q|train|      Master. Eugene|Master|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|29.69911764705882|    0|    0|          244373|   13.0|       S|train|  Mr. Charles Eugene|    Mr|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|             31.0|    1|    0|          345763|   18.0|       S|train|Mrs. Julius (Emel...|   Mrs|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|29.69911764705882|    0|    0|            2649|  7.225|       C|train|         Mrs. Fatima|   Mrs|\n",
      "+-----------+--------+------+--------------------+------+-----------------+-----+-----+----------------+-------+--------+-----+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
